# Text Normalization
Text normalization is a preprocessing step that puts words/tokens in a canonicalized form.

Solutions:
- Remove comon substrings (stemming/lemmatization)
- Replace with vectors (embeddings)
- Mapping everything to lower case (case folding)

## Before Normalization...
1. Tokenize, or segment, words (byte-pair encoding useful to know since e.g. BERT uses bpe)
2. Normalize word formats
3. Segmenting sentences

## Minimum Edit Distance:
see more...

## Byte Pair Encoding
Working on implementation... Click *insert link* to tokenization folder.
